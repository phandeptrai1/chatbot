import os
import json
import discord
from discord.ext import commands
from google import genai
from google.genai import types

# Láº¥y biáº¿n mÃ´i trÆ°á»ng
DISCORD_TOKEN = os.environ["DISCORD_TOKEN"]
GEMINI_API_KEY = os.environ["GEMINI_API_KEY"]

# Cáº¥u hÃ¬nh Gemini
client = genai.Client(api_key=GEMINI_API_KEY)
model = "gemini-2.0-flash"

# Cáº¥u hÃ¬nh Discord bot
intents = discord.Intents.default()
intents.message_content = True
bot = commands.Bot(command_prefix="!", intents=intents)

# ÄÆ°á»ng dáº«n file lÆ°u lá»‹ch sá»­
HISTORY_FILE = "history/thuy.json"

# HÃ m Ä‘á»c lá»‹ch sá»­ tá»« file
def load_history():
    if not os.path.exists(HISTORY_FILE):
        return []
    try:
        with open(HISTORY_FILE, "r", encoding="utf-8") as f:
            content = f.read().strip()
            if not content:
                return []  # Náº¿u file rá»—ng
            raw = json.loads(content)
            return [types.Content(**msg) for msg in raw]
    except Exception as e:
        print(f"ğŸ“› Lá»—i khi load history: {e}")
        return []

# HÃ m ghi lá»‹ch sá»­ vÃ o file
def save_history(history):
    try:
        os.makedirs(os.path.dirname(HISTORY_FILE), exist_ok=True)
        raw = [msg.model_dump() for msg in history]
        with open(HISTORY_FILE, "w", encoding="utf-8") as f:
            json.dump(raw, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"ğŸ“› Lá»—i khi lÆ°u history: {e}")

@bot.event
async def on_ready():
    print(f"ğŸ° TÃº Ä‘Ã£ online dÆ°á»›i tÃªn: {bot.user}")

@bot.command(name="ask")
async def ask_tu(ctx, *, prompt: str):
    await ctx.send("ğŸ’­ Äá»£i xÃ­u ThÃºy Æ¡i...")

    try:
        # Load lá»‹ch sá»­ tá»« file
        history = load_history()[-6:]

        # Prompt vai trÃ² ban Ä‘áº§u
        messages = [
            types.Content(
                role="user",
                parts=[types.Part.from_text(text=(
                    "Báº¡n tÃªn lÃ  TÃº, AI dá»… thÆ°Æ¡ng nÃ³i chuyá»‡n thÃ¢n máº­t vá»›i ThÃºy ğŸ°. "
                    "Gá»i ThÃºy báº±ng tÃªn, dÃ¹ng nhiá»u icon dá»… thÆ°Æ¡ng nhÆ° ğŸ¥ºğŸ’–ğŸŒ¸."
                ))]
            )
        ]
        messages.extend(history)

        # CÃ¢u má»›i cá»§a ThÃºy
        new_user_msg = types.Content(role="user", parts=[types.Part.from_text(text=prompt)])
        messages.append(new_user_msg)

        # Gá»­i tá»›i Gemini
        config = types.GenerateContentConfig(response_mime_type="text/plain")
        reply = ""

        for chunk in client.models.generate_content_stream(
            model=model,
            contents=messages,
            config=config,
        ):
            if chunk.text:
                reply += chunk.text

        await ctx.send(f"ğŸŒ¸ **TÃº:** {reply}")

        # LÆ°u láº¡i lá»‹ch sá»­
        history.append(new_user_msg)
        history.append(types.Content(role="model", parts=[types.Part.from_text(text=reply)]))
        save_history(history)

    except Exception as e:
        await ctx.send(f"âŒ TÃº lá»—i rÃ¹i ThÃºy Æ¡i: `{str(e)}`")

bot.run(DISCORD_TOKEN)
